{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e68b829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from dnafiber.inference import _get_model\n",
    "import math\n",
    "import time\n",
    "from dnafiber.postprocess.core import Fibers\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from dnafiber.postprocess.error_detection import load_model\n",
    "from dnafiber.postprocess import refine_segmentation\n",
    "from dnafiber.ui.inference import ui_inference_cacheless\n",
    "from dnafiber.ui.utils import (\n",
    "    get_image_cacheless,\n",
    ")\n",
    "from dnafiber.deployment import ENSEMBLE, Models\n",
    "\n",
    "for name, l in logging.root.manager.loggerDict.items():\n",
    "    if \"streamlit\" in name:\n",
    "        l.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c819c5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 17.35it/s], ?it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.95it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.60it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.68it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 17.31it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.88it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.89it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.94it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.29it/s]1:50, 110.77s/it]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.40it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.28it/s]\n",
      "Processing files: 100%|██████████| 2/2 [02:47<00:00, 83.90s/it] \n"
     ]
    }
   ],
   "source": [
    "reverse_channels = False\n",
    "sint_file = Path(\"/home/clement/Documents/data/DNAFiber/Input/YM-2025-20/2025-05-16/siNT-01.czi\")\n",
    "sibrca1_file = Path(\"/home/clement/Documents/data/DNAFiber/Input/YM-2025-20/2025-05-16/siBRCA1-01.czi\")\n",
    "\n",
    "# model2  = _get_model(\"segformer_mit_b4_finetuned\").cuda()\n",
    "detection_model = None\n",
    "# model = [model1, model2]\n",
    "all_results_blurred = []\n",
    "all_images_blurred = []\n",
    "\n",
    "for file in tqdm([sint_file,  sibrca1_file], desc=\"Processing files\"):\n",
    "    image = get_image_cacheless(file, False)\n",
    "   \n",
    "    for sigma in np.arange(0, 8, 1):\n",
    "        ksize = int(2 * math.ceil(3 * sigma) + 1)\n",
    "        gaussian_blurred = cv2.GaussianBlur(image, (ksize, ksize), sigma)\n",
    "        all_images_blurred.append(gaussian_blurred)\n",
    "        start = time.time()\n",
    "        prediction: Fibers = ui_inference_cacheless(\n",
    "            _model=Models.UNET_MOBILEONE_S0,\n",
    "            _image=gaussian_blurred,\n",
    "            _device=\"cuda\",\n",
    "            use_tta=False,\n",
    "            pixel_size=0.13,\n",
    "            only_segmentation=False,\n",
    "            use_correction=None,\n",
    "        )\n",
    "        df = prediction.to_df(img_name=file.stem, filter_invalid=False)\n",
    "        df[\"Type\"] = '-'.join(file.stem.split(\"-\")[:-1])\n",
    "        df[\"sigma\"] = sigma\n",
    "        all_results_blurred.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cec959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ccc6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/2 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ui_inference_cacheless() missing 1 required positional argument: 'pixel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m all_images_noise.append(noisy)\n\u001b[32m     11\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m prediction = \u001b[43mui_inference_cacheless\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mModels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUNET_MOBILEONE_S0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnoisy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_device\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tta\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_segmentation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_correction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrediction time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m results = [fiber \u001b[38;5;28;01mfor\u001b[39;00m fiber \u001b[38;5;129;01min\u001b[39;00m prediction]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dnafiber/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: ui_inference_cacheless() missing 1 required positional argument: 'pixel_size'"
     ]
    }
   ],
   "source": [
    "from skimage.util import random_noise\n",
    "\n",
    "all_results_noise = []\n",
    "all_images_noise = []\n",
    "for file in tqdm([sint_file, sibrca1_file], desc=\"Processing files\"):\n",
    "    image = get_image_cacheless(file, False)\n",
    "    for sigma in np.linspace(0, 0.5, 8):\n",
    "        noisy = random_noise(image, mode='gaussian', var=sigma**2, clip=True) * 255\n",
    "        noisy = noisy.astype(np.uint8)\n",
    "        all_images_noise.append(noisy)\n",
    "        start = time.time()\n",
    "        prediction: Fibers = ui_inference_cacheless(\n",
    "            _model=Models.UNET_MOBILEONE_S0,\n",
    "            _image=noisy,\n",
    "            _device=\"cuda\",\n",
    "            use_tta=False,\n",
    "            pixel_size=0.13,\n",
    "            only_segmentation=False,\n",
    "            use_correction=None,\n",
    "        )\n",
    "        df = prediction.to_df(img_name=file.stem, filter_invalid=False)\n",
    "        df[\"Type\"] = '-'.join(file.stem.split(\"-\")[:-1])\n",
    "        df[\"sigma\"] = sigma\n",
    "        all_results_noise.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a15f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mall_results_noise\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'all_results_noise' is not defined"
     ]
    }
   ],
   "source": [
    "all_results_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d67156",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m df_blurred = df_blurred[df_blurred[\u001b[33m\"\u001b[39m\u001b[33mRatio\u001b[39m\u001b[33m\"\u001b[39m] <\u001b[32m10\u001b[39m]\n\u001b[32m      8\u001b[39m df_blurred = df_blurred[df_blurred[\u001b[33m\"\u001b[39m\u001b[33mRatio\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0.125\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df_noise = pd.concat(\u001b[43mall_results_noise\u001b[49m, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m df_noise[\u001b[33m\"\u001b[39m\u001b[33msigma\u001b[39m\u001b[33m\"\u001b[39m] = df_noise[\u001b[33m\"\u001b[39m\u001b[33msigma\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m df_noise[\u001b[33m\"\u001b[39m\u001b[33mRatio\u001b[39m\u001b[33m\"\u001b[39m] = df_noise[\u001b[33m\"\u001b[39m\u001b[33mRatio\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'all_results_noise' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import Path\n",
    "\n",
    "df_blurred = pd.concat(all_results_blurred, ignore_index=True)\n",
    "df_blurred[\"sigma\"] = df_blurred[\"sigma\"].astype(str)\n",
    "df_blurred[\"Ratio\"] = df_blurred[\"Ratio\"].astype(float)\n",
    "df_blurred = df_blurred[df_blurred[\"Ratio\"] <10]\n",
    "df_blurred = df_blurred[df_blurred[\"Ratio\"] > 0.125]\n",
    "df_noise = pd.concat(all_results_noise, ignore_index=True)\n",
    "df_noise[\"sigma\"] = df_noise[\"sigma\"]\n",
    "df_noise[\"Ratio\"] = df_noise[\"Ratio\"].astype(float)\n",
    "df_noise = df_noise[df_noise[\"Ratio\"] <10]\n",
    "df_noise = df_noise[df_noise[\"Ratio\"] > 0.125]\n",
    "\n",
    "median_baseline = df_blurred[df_blurred[\"sigma\"] == \"0\"].groupby(\"Type\")[\"Ratio\"].median().reset_index()\n",
    "median_value = median_baseline[median_baseline[\"Type\"] == \"siNT\"][\"Ratio\"]\n",
    "# df_blurred[\"Ratio\"] = df_blurred[\"Ratio\"] / median_value.values[0]\n",
    "\n",
    "median_baseline = df_noise[df_noise[\"sigma\"] == 0].groupby(\"Type\")[\"Ratio\"].median().reset_index()\n",
    "median_value = median_baseline[median_baseline[\"Type\"] == \"siNT\"][\"Ratio\"]\n",
    "# df_noise[\"Ratio\"] = df_noise[\"Ratio\"] / median_value.values[0]\n",
    "\n",
    "# Order the dataframe by order: [\"siNT\",\"siBRCA1\", \"siBRCA2\"]\n",
    "order = [\"siNT\", \"siBRCA1\"]\n",
    "df_blurred[\"Type\"] = pd.Categorical(df_blurred[\"Type\"], categories=order, ordered=True)\n",
    "df_noise[\"Type\"] = pd.Categorical(df_noise[\"Type\"], categories=order, ordered=True)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 8), sharey=False)\n",
    "\n",
    "palette = [\"#e78284\", \"#81c8be\", \"#8caaee\"]\n",
    "for i, (ax, df, title) in enumerate(zip(axes[1, :], [df_blurred, df_noise], [\"Gaussian Blurring\", \"Gaussian Noise\"])):\n",
    "    sns.boxenplot(\n",
    "        x=\"sigma\",\n",
    "        y=\"Ratio\",\n",
    "        hue=\"Type\",\n",
    "        data=df,\n",
    "        ax=ax,\n",
    "        palette=palette,\n",
    "    )\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(r\"Normalized Ratio (by siNT median at $\\sigma$=0)\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(r\"Standard Deviation ($\\sigma$)\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_yticks([0.125, 0.25, 0.5, 1, 2, 4, 8], \n",
    "                  [0.125, 0.25, 0.5, 1, 2, 4, 8])\n",
    "    ax.set_ylim(0.125, 32)\n",
    "    ax.minorticks_off()\n",
    "    ax.legend(title=\"Type\", loc=\"upper right\", ncol=3)\n",
    "    if title == \"Gaussian Noise\":\n",
    "        ax.set_xticklabels([f\"{sigma:.2f}\" for sigma in df[\"sigma\"].unique()])\n",
    "\n",
    "    # Add text to indicate the number of fibers per sigma and type\n",
    "    for i, sigma in enumerate(df[\"sigma\"].unique()):\n",
    "        for j, fiber_type in enumerate(df[\"Type\"].unique()):\n",
    "            count = df[(df[\"sigma\"] == sigma) & (df[\"Type\"] == fiber_type)].shape[0]\n",
    "            ax.text(i+j/3.5 - 1/3, 7, f\"N=\\n{count}\", ha='center', va='bottom', fontsize=8, color='black')\n",
    "\n",
    "start = 4096\n",
    "length = 512\n",
    "subset_indices_y = slice(start, start + length)\n",
    "subset_indices_x = slice(start, start + length)\n",
    "for i, (ax, df, title) in enumerate(zip(axes[0, :], [df_blurred, df_noise], [\"Gaussian Blurring\", \"Gaussian Additive Noise\"])):\n",
    "    sigmas = df[\"sigma\"].unique()\n",
    "    current_list = all_images_blurred if i == 0 else all_images_noise\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(0, len(sigmas))\n",
    "    ax.set_yscale(\"linear\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title)\n",
    "\n",
    "    for j, s in enumerate(sigmas):\n",
    "        img1 = current_list[j][subset_indices_y, subset_indices_x]\n",
    "        ax.imshow(img1, extent=[j, j+1, 0, 1])\n",
    "        ax.axvline(j , color='white', linestyle='--', linewidth=1)\n",
    "        \n",
    "        \n",
    "# Reduce the margin between the subplots\n",
    "plt.subplots_adjust(hspace=0., wspace=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnafiber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
